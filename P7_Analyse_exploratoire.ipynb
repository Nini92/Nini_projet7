{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e93fc20",
   "metadata": {},
   "source": [
    "# Import nécessaires \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdcf26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a9baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour fractionner et nettoyer un fichier CSV par morceaux\n",
    "def process_csv_in_chunks(file_path, chunk_size=10000, expected_columns=122, sample_fraction=0.10):\n",
    "    base_name = os.path.splitext(file_path)[0]\n",
    "    chunk_number = 0\n",
    "    cleaned_samples = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)\n",
    "        chunk = [header]\n",
    "        \n",
    "        for i, line in enumerate(reader):\n",
    "            if (i + 1) % chunk_size == 0:\n",
    "                chunk.append(line)\n",
    "                cleaned_chunk = clean_chunk(chunk, expected_columns)\n",
    "                sample_chunk = sample_chunk_data(cleaned_chunk, sample_fraction)\n",
    "                cleaned_samples.append(sample_chunk)\n",
    "                chunk_number += 1\n",
    "                chunk = [header]\n",
    "            else:\n",
    "                chunk.append(line)\n",
    "        \n",
    "        # Process remaining lines\n",
    "        if chunk:\n",
    "            cleaned_chunk = clean_chunk(chunk, expected_columns)\n",
    "            sample_chunk = sample_chunk_data(cleaned_chunk, sample_fraction)\n",
    "            cleaned_samples.append(sample_chunk)\n",
    "    \n",
    "    # Combine all cleaned samples into a single DataFrame\n",
    "    final_sample = pd.concat(cleaned_samples, axis=0)\n",
    "    return final_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d386e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour nettoyer un morceau de données\n",
    "def clean_chunk(chunk, expected_columns):\n",
    "    cleaned_chunk = [chunk[0]]  # Ajouter l'en-tête\n",
    "    for row in chunk[1:]:\n",
    "        if len(row) == expected_columns:\n",
    "            cleaned_chunk.append(row)\n",
    "    return cleaned_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394255b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour échantillonner un morceau de données\n",
    "def sample_chunk_data(chunk, sample_fraction):\n",
    "    df_chunk = pd.DataFrame(chunk[1:], columns=chunk[0])\n",
    "    sample_chunk = df_chunk.sample(frac=sample_fraction, random_state=1)\n",
    "    return sample_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ecd0606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./application_train.csv...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './application_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file, col_count \u001b[38;5;129;01min\u001b[39;00m files_and_columns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     cleaned_samples[file] \u001b[38;5;241m=\u001b[39m process_csv_in_chunks(file, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, expected_columns\u001b[38;5;241m=\u001b[39mcol_count, sample_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.10\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cleaned_samples[file]\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mprocess_csv_in_chunks\u001b[1;34m(file_path, chunk_size, expected_columns, sample_fraction)\u001b[0m\n\u001b[0;32m      4\u001b[0m chunk_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m cleaned_samples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      8\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(file)\n\u001b[0;32m      9\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(reader)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './application_train.csv'"
     ]
    }
   ],
   "source": [
    "# Liste des fichiers et leurs colonnes attendues\n",
    "files_and_columns = {\n",
    "    './application_train.csv': 122,\n",
    "    './application_test.csv': 121,\n",
    "}\n",
    "\n",
    "# Processer chaque fichier CSV et sauvegarder les fragments propres\n",
    "cleaned_samples = {}\n",
    "for file, col_count in files_and_columns.items():\n",
    "    print(f\"Processing {file}...\")\n",
    "    cleaned_samples[file] = process_csv_in_chunks(file, chunk_size=10000, expected_columns=col_count, sample_fraction=0.10)\n",
    "    print(f\"Finished processing {file}.\")\n",
    "    print(cleaned_samples[file].head())\n",
    "    cleaned_samples[file].to_csv(f'cleaned_{os.path.basename(file)}', index=False)  # Sauvegarder les fragments propres\n",
    "    gc.collect()  # Nettoyer la mémoire après chaque fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46164227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fonction pour traiter les valeurs manquantes et encoder les variables catégorielles\n",
    "def preprocess_data(df):\n",
    "    # Séparation des colonnes numériques et catégorielles\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Imputation des valeurs manquantes pour les colonnes numériques uniquement\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "    \n",
    "    # Encodage des variables catégorielles\n",
    "    df = pd.get_dummies(df, columns=categorical_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour normaliser les données\n",
    "def normalize_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les fichiers nettoyés\n",
    "application_train = pd.read_csv('cleaned_application_train.csv')\n",
    "application_test = pd.read_csv('cleaned_application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce713bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = preprocess_data(application_train)\n",
    "application_test = preprocess_data(application_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4697f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser chaque fichier\n",
    "application_train = normalize_data(application_train)\n",
    "# application_test = normalize_data(application_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les fichiers nettoyés\n",
    "application_train = pd.read_csv('cleaned_application_train.csv')\n",
    "\n",
    "# Imputation des valeurs manquantes pour les colonnes numériques\n",
    "numeric_cols = application_train.select_dtypes(include=['number']).columns\n",
    "application_train[numeric_cols] = application_train[numeric_cols].fillna(application_train[numeric_cols].mean())\n",
    "\n",
    "# Vérifier les types de colonnes\n",
    "print(\"Types de colonnes avant la suppression des colonnes non numériques :\")\n",
    "print(application_train.dtypes)\n",
    "\n",
    "# Suppression des colonnes non numériques\n",
    "application_train = application_train.select_dtypes(include=[float, int])\n",
    "\n",
    "# Vérifier les types de colonnes après suppression\n",
    "print(\"Types de colonnes après la suppression des colonnes non numériques :\")\n",
    "print(application_train.dtypes)\n",
    "\n",
    "# Séparer les caractéristiques et la cible\n",
    "X = application_train.drop('TARGET', axis=1)\n",
    "y = application_train['TARGET']\n",
    "\n",
    "# Diviser les données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Appliquer SMOTE à l'ensemble d'entraînement\n",
    "smote = SMOTE(random_state=1)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f88110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "file_path = './data.csv'\n",
    "application_train.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les paramètres pour la recherche par grille\n",
    "param_grid_lr = {\n",
    "    'solver': ['liblinear'],\n",
    "    'C': [0.1],\n",
    "    'max_iter': [1000 ]\n",
    "}\n",
    "\n",
    "# Définir les paramètres pour la recherche par grille\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [1, 10],\n",
    "    'max_depth': [ None],\n",
    "    'min_samples_split': [2]\n",
    "}\n",
    "\n",
    "# Définir les paramètres pour la recherche par grille\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [1, 10],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [5]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'expérience MLFlow\n",
    "mlflow.set_experiment(\"Model Tracking and Registry\")\n",
    "\n",
    "# Fonction pour enregistrer les métriques avec MLFlow\n",
    "def log_metrics_with_business_cost(model_name, best_model, X_test, y_test, y_pred_proba, fn_cost=10, fp_cost=1):\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_test, (y_pred_proba >= 0.5).astype(int))\n",
    "    precision = precision_score(y_test, (y_pred_proba >= 0.5).astype(int))\n",
    "    recall = recall_score(y_test, (y_pred_proba >= 0.5).astype(int))\n",
    "    conf_matrix = confusion_matrix(y_test, (y_pred_proba >= 0.5).astype(int))\n",
    "    \n",
    "    best_threshold, best_cost = find_best_threshold(y_test, y_pred_proba, fn_cost, fp_cost)\n",
    "    business_cost, y_pred_optimized = calculate_business_cost(y_test, y_pred_proba, best_threshold, fn_cost, fp_cost)\n",
    "    \n",
    "    mlflow.log_param(\"Model\", model_name)\n",
    "    mlflow.log_param(\"Best Params\", best_model.get_params())\n",
    "    mlflow.log_param(\"Best Threshold\", best_threshold)\n",
    "    mlflow.log_metric(\"AUC\", auc)\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"Precision\", precision)\n",
    "    mlflow.log_metric(\"Recall\", recall)\n",
    "    mlflow.log_metric(\"Business Cost\", business_cost)\n",
    "    mlflow.sklearn.log_model(best_model, model_name)\n",
    "    \n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Best Threshold: {best_threshold}\")\n",
    "    print(f\"Business Cost: {business_cost}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "def calculate_business_cost(y_true, y_pred_proba, threshold, fn_cost=10, fp_cost=1):\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    cost = fn * fn_cost + fp * fp_cost\n",
    "    return cost, y_pred\n",
    "\n",
    "def find_best_threshold(y_true, y_pred_proba, fn_cost=10, fp_cost=1):\n",
    "    thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "    costs = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        cost, _ = calculate_business_cost(y_true, y_pred_proba, threshold, fn_cost, fp_cost)\n",
    "        costs.append((cost, threshold))\n",
    "    \n",
    "    best_cost, best_threshold = min(costs, key=lambda x: x[0])\n",
    "    return best_threshold, best_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed0bc4",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Entraîner et enregistrer les modèles avec GridSearchCV\n",
    "with mlflow.start_run(run_name=\"Logistic Regression\") as run:\n",
    "    lr = LogisticRegression(random_state=1)\n",
    "    grid_lr = GridSearchCV(lr, param_grid_lr, cv=5, scoring='roc_auc')\n",
    "    grid_lr.fit(X_train_smote, y_train_smote)\n",
    "    best_lr = grid_lr.best_estimator_\n",
    "    y_pred_proba_lr = best_lr.predict_proba(X_test)[:, 1]\n",
    "    log_metrics_with_business_cost(\"Logistic Regression\", best_lr, X_test, y_test, y_pred_proba_lr)\n",
    "    lr_run_id = run.info.run_id  # Obtenir l'ID de run pour l'enregistrement du modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227efeb",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02442712",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Random Forest\") as run:\n",
    "    rf = RandomForestClassifier(random_state=1)\n",
    "    grid_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='roc_auc')\n",
    "    grid_rf.fit(X_train_smote, y_train_smote)\n",
    "    best_rf = grid_rf.best_estimator_\n",
    "    y_pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "    log_metrics_with_business_cost(\"Random Forest\", best_rf, X_test, y_test, y_pred_proba_rf)\n",
    "    rf_run_id = run.info.run_id  # Obtenir l'ID de run pour l'enregistrement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1d4d70",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6260c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Gradient Boosting\") as run:\n",
    "    gb = GradientBoostingClassifier(random_state=1)\n",
    "    grid_gb = GridSearchCV(gb, param_grid_gb, cv=5, scoring='roc_auc')\n",
    "    grid_gb.fit(X_train_smote, y_train_smote)\n",
    "    best_gb = grid_gb.best_estimator_\n",
    "    y_pred_proba_gb = best_gb.predict_proba(X_test)[:, 1]\n",
    "    log_metrics_with_business_cost(\"Gradient Boosting\", best_gb, X_test, y_test, y_pred_proba_gb)\n",
    "    gb_run_id = run.info.run_id  # Obtenir l'ID de run pour l'enregistrement du modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94887685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement des modèles dans le registry\n",
    "mlflow.register_model(f\"runs:/{lr_run_id}/model\", \"LogisticRegressionModel\")\n",
    "mlflow.register_model(f\"runs:/{rf_run_id}/model\", \"RandomForestModel\")\n",
    "mlflow.register_model(f\"runs:/{gb_run_id}/model\", \"GradientBoostingModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5504841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Lancer le serveur MLflow en arrière-plan\n",
    "subprocess.Popen([\"mlflow\", \"ui\", \"--port\", \"5000\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23839e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "\n",
    "# Afficher le lien pour accéder à l'interface utilisateur de MLflow\n",
    "display.display(display.Javascript('window.open(\"//localhost:5000\", \"_blank\");'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd C:\\Users\\Foudil\n",
    "# !git init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Ajouter les fichiers à l'index\n",
    "# os.system(\"git add P7_Analyse_exploratoire.ipynb cleaned_application_train.csv\")\n",
    "\n",
    "# # Faire un commit avec un message approprié\n",
    "# os.system('git commit -m \"Initial commit with analysis and data, ignoring large files\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09831ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import subprocess\n",
    "\n",
    "# # Fonction pour exécuter une commande et capturer la sortie et les erreurs\n",
    "# def run_command(command):\n",
    "#     result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "#     print(\"Output:\", result.stdout)\n",
    "#     print(\"Error:\", result.stderr)\n",
    "#     return result.returncode\n",
    "\n",
    "# # Retirer le fichier volumineux de l'index Git\n",
    "# # run_command(\"git rm --cached datap7/application_train_cleaned.csv\")\n",
    "\n",
    "# # Ajouter .gitignore à l'index\n",
    "# # run_command(\"git add .gitignore\")\n",
    "\n",
    "# # Faire un commit avec un message approprié\n",
    "# run_command('git commit -m \"Remove large file from version control\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Ajouter les fichiers à l'index\n",
    "# os.system(\"git add P7_Analyse_exploratoire.ipynb cleaned_application_train.csv\")\n",
    "\n",
    "# # Faire un commit avec un message approprié\n",
    "# os.system('git commit -m \"Initial commit with analysis and data\"')\n",
    "\n",
    "# # Pousser les changements vers GitHub\n",
    "# os.system(\"git push -u origin main\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949268ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name: CI\n",
    "\n",
    "# on: [push]\n",
    "\n",
    "# jobs:\n",
    "#   build:\n",
    "#     runs-on: ubuntu-latest\n",
    "\n",
    "#     steps:\n",
    "#       - uses: actions/checkout@v2\n",
    "#       - name: Set up Python\n",
    "#         uses: actions/setup-python@v2\n",
    "#         with:\n",
    "#           python-version: 3.x\n",
    "#       - name: Install dependencies\n",
    "#         run: |\n",
    "#           python -m pip install --upgrade pip\n",
    "#           pip install -r requirements.txt\n",
    "#       - name: Run tests\n",
    "#         run: |\n",
    "#           pytest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f6f76",
   "metadata": {},
   "source": [
    "http://localhost:5000 MLFlow UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041286a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_ratios = [(5, 1), (10, 1), (20, 1)]\n",
    "\n",
    "def evaluate_cost_ratios(y_test, y_pred_proba, cost_ratios):\n",
    "    results = []\n",
    "    for fn_cost, fp_cost in cost_ratios:\n",
    "        best_threshold, business_cost = find_best_threshold(y_test, y_pred_proba, fn_cost, fp_cost)\n",
    "        results.append({\n",
    "            'FN Cost': fn_cost,\n",
    "            'FP Cost': fp_cost,\n",
    "            'Best Threshold': best_threshold,\n",
    "            'Business Cost': business_cost\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lr = evaluate_cost_ratios(y_test, y_pred_proba_lr, cost_ratios)\n",
    "print(\"\\n=== Logistic Regression Costs ===\")\n",
    "print(pd.DataFrame(results_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf = evaluate_cost_ratios(y_test, y_pred_proba_rf, cost_ratios)\n",
    "print(\"\\n=== Random Forest Costs ===\")\n",
    "print(pd.DataFrame(results_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gb = evaluate_cost_ratios(y_test, y_pred_proba_gb, cost_ratios)\n",
    "print(\"\\n=== Gradient Boosting Costs ===\")\n",
    "print(pd.DataFrame(results_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8564e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def compare_models(cost_ratios, results_lr, results_rf, results_gb):\n",
    "    comparison = []\n",
    "    for i, (fn_cost, fp_cost) in enumerate(cost_ratios):\n",
    "        comparison.append({\n",
    "            'Model': 'Logistic Regression',\n",
    "            'FN Cost': fn_cost,\n",
    "            'FP Cost': fp_cost,\n",
    "            'Best Threshold': results_lr[i]['Best Threshold'],\n",
    "            'Business Cost': results_lr[i]['Business Cost']\n",
    "        })\n",
    "        comparison.append({\n",
    "            'Model': 'Random Forest',\n",
    "            'FN Cost': fn_cost,\n",
    "            'FP Cost': fp_cost,\n",
    "            'Best Threshold': results_rf[i]['Best Threshold'],\n",
    "            'Business Cost': results_rf[i]['Business Cost']\n",
    "        })\n",
    "        comparison.append({\n",
    "            'Model': 'Gradient Boosting',\n",
    "            'FN Cost': fn_cost,\n",
    "            'FP Cost': fp_cost,\n",
    "            'Best Threshold': results_gb[i]['Best Threshold'],\n",
    "            'Business Cost': results_gb[i]['Business Cost']\n",
    "        })\n",
    "    return pd.DataFrame(comparison)\n",
    "\n",
    "comparison_df = compare_models(cost_ratios, results_lr, results_rf, results_gb)\n",
    "print(\"\\n=== Model Comparison with Different Cost Ratios ===\")\n",
    "print(comparison_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d3797",
   "metadata": {},
   "source": [
    "Business Cost by Model and FN Cost : Ce graphique montre le coût métier pour chaque modèle en fonction du coût des faux négatifs. On observe que le modèle Random Forest avec un coût FN de 5 a le coût métier le plus bas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=comparison_df, x='Model', y='Business Cost', hue='FN Cost')\n",
    "plt.title('Business Cost by Model and FN Cost')\n",
    "plt.ylabel('Business Cost')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(title='FN Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300eaa6",
   "metadata": {},
   "source": [
    "Best Threshold by Model and FN Cost : Ce graphique montre le meilleur seuil pour chaque modèle en fonction du coût des faux négatifs. On observe que les seuils varient significativement en fonction du coût FN et du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa332bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=comparison_df, x='Model', y='Best Threshold', hue='FN Cost')\n",
    "plt.title('Best Threshold by Model and FN Cost')\n",
    "plt.ylabel('Best Threshold')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(title='FN Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79da83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créer l'objet explainer SHAP\n",
    "explainer_lr = shap.Explainer(best_lr, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les valeurs SHAP pour l'ensemble de test\n",
    "shap_values_lr = explainer_lr(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de JavaScript pour les visualisations SHAP\n",
    "shap.initjs()\n",
    "\n",
    "# Visualisation des valeurs SHAP pour une prédiction individuelle\n",
    "shap.force_plot(shap_values_lr[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation globale des valeurs SHAP\n",
    "shap.summary_plot(shap_values_lr, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4021a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les valeurs SHAP\n",
    "shap_values_array = shap_values_lr.values if hasattr(shap_values_lr, 'values') else shap_values_lr\n",
    "\n",
    "# Extraire les indices des 10 caractéristiques les plus importantes\n",
    "importances = np.abs(shap_values_array).mean(axis=0)\n",
    "indices = np.argsort(importances)[-10:]  # Obtenir les indices des 10 caractéristiques les plus importantes\n",
    "important_features = X_test.columns[indices]\n",
    "print(\"Les 10 caractéristiques les plus importantes sont :\")\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créer l'objet explainer SHAP\n",
    "explainer_rf = shap.Explainer(best_rf, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdb69ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les SHAP explainers pour chaque modèle avec check_additivity=False\n",
    "explainers = {\n",
    "    \"Random Forest\": shap.TreeExplainer(best_rf, check_additivity=False),\n",
    "    \"Gradient Boosting\": shap.TreeExplainer(best_gb, check_additivity=False),\n",
    "    \"Logistic Regression\": shap.LinearExplainer(best_lr, X_train, check_additivity=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c35471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import traceback\n",
    "\n",
    "# Essayer de charger le modèle de scoring\n",
    "try:\n",
    "    with open('best_lr_important.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(\"Modèle chargé avec succès.\")\n",
    "except Exception as e:\n",
    "    print(\"Erreur lors du chargement du modèle :\", e)\n",
    "    print(traceback.format_exc())\n",
    "\n",
    "# Essayer de charger les données du fichier CSV\n",
    "try:\n",
    "    df = pd.read_csv('cleaned_application_test.csv')\n",
    "    print(\"Données chargées avec succès.\")\n",
    "except Exception as e:\n",
    "    print(\"Erreur lors du chargement des données :\", e)\n",
    "    print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Obtenir le chemin absolu du répertoire courant\n",
    "chemin_projet = os.getcwd()\n",
    "print(\"Chemin du projet :\", chemin_projet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a826c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Supposez que best_lr est votre modèle de régression logistique déjà entraîné\n",
    "with open('best_lr.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_lr, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f72dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Fonction pour faire une requête à l'API et obtenir des prédictions pour un client spécifique\n",
    "def get_client_prediction(client_id, api_url):\n",
    "    try:\n",
    "        data = {\"client_id\": client_id}\n",
    "        response = requests.post(api_url, json=data)\n",
    "        print(f\"Status code: {response.status_code}\")  # Afficher le code de statut HTTP\n",
    "        print(f\"Response content: {response.content}\")  # Afficher le contenu de la réponse\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# URL de l'API (à remplacer par l'URL réelle de votre API)\n",
    "api_url = \"https://foudilnini.pythonanywhere.com/predict\"\n",
    "\n",
    "# Sélectionner un client pour la prédiction\n",
    "client_id = 243566# Remplacez par l'ID du client que vous souhaitez prédire\n",
    "\n",
    "# Obtenir la prédiction pour le client sélectionné\n",
    "prediction = get_client_prediction(client_id, api_url)\n",
    "\n",
    "# Afficher la prédiction\n",
    "if prediction:\n",
    "    print(f\"Prediction for client {client_id}: {prediction}\")\n",
    "else:\n",
    "    print(f\"Failed to get prediction for client {client_id}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7d4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afac31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
